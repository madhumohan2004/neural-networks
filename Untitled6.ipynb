{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7S-wNK9HJC4s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data=pd.read_csv(\"Iris.csv\")"
      ],
      "metadata": {
        "id": "3zezC1kRJSKj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the target column and transform the target column\n",
        "iris_data['species_encoded'] = label_encoder.fit_transform(iris_data['Species'])\n",
        "\n",
        "# You can see the mapping of original labels to encoded labels using classes_ attribute\n",
        "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "# Print the mapping\n",
        "print(class_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1xUmZ9dKQ8I",
        "outputId": "285988d4-6152-4a41-bbfd-8d58f5adab03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into features (X) and the target (y)\n",
        "X = iris_data.drop(columns=['Species', 'species_encoded'])\n",
        "y = iris_data['species_encoded']\n",
        "\n",
        "# Split the data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# The 'test_size' parameter determines the percentage of the data to be used for testing (in this case, 20%).\n",
        "# You can change the 'random_state' to any integer for reproducibility.\n",
        "\n",
        "# Now you have X_train, X_test, y_train, and y_test, which are your training and testing data and labels.\n"
      ],
      "metadata": {
        "id": "N94LzD_eNocx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess the data\n",
        "iris_data = pd.read_csv('Iris.csv')\n",
        "label_encoder = LabelEncoder()\n",
        "iris_data['species_encoded'] = label_encoder.fit_transform(iris_data['Species'])\n",
        "\n",
        "X = iris_data.drop(columns=['Species', 'species_encoded'])\n",
        "y = iris_data['species_encoded']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_dim=5),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(3, activation='softmax')  # 3 output units for the 3 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8YD__A0QBY-",
        "outputId": "88c5226f-2fc8-4ac3-cec0-8bb62e0e69dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 68ms/step - loss: 1.1950 - accuracy: 0.2667 - val_loss: 1.0860 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0228 - accuracy: 0.5417 - val_loss: 0.9190 - val_accuracy: 0.7667\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8820 - accuracy: 0.8333 - val_loss: 0.7850 - val_accuracy: 0.9667\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7682 - accuracy: 0.8833 - val_loss: 0.6783 - val_accuracy: 0.9333\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.6789 - accuracy: 0.8750 - val_loss: 0.5928 - val_accuracy: 0.9000\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6065 - accuracy: 0.8583 - val_loss: 0.5234 - val_accuracy: 0.9000\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5473 - accuracy: 0.8667 - val_loss: 0.4660 - val_accuracy: 0.9000\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4981 - accuracy: 0.8750 - val_loss: 0.4176 - val_accuracy: 0.9000\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4556 - accuracy: 0.8750 - val_loss: 0.3760 - val_accuracy: 0.9333\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4184 - accuracy: 0.8750 - val_loss: 0.3400 - val_accuracy: 0.9333\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3862 - accuracy: 0.8917 - val_loss: 0.3085 - val_accuracy: 0.9667\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3564 - accuracy: 0.9000 - val_loss: 0.2807 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3307 - accuracy: 0.9083 - val_loss: 0.2547 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3054 - accuracy: 0.9167 - val_loss: 0.2307 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2818 - accuracy: 0.9250 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2625 - accuracy: 0.9250 - val_loss: 0.1897 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2439 - accuracy: 0.9417 - val_loss: 0.1730 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2259 - accuracy: 0.9500 - val_loss: 0.1573 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2093 - accuracy: 0.9500 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1958 - accuracy: 0.9500 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1827 - accuracy: 0.9500 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1714 - accuracy: 0.9500 - val_loss: 0.1078 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1602 - accuracy: 0.9500 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1496 - accuracy: 0.9500 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1408 - accuracy: 0.9500 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1313 - accuracy: 0.9583 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1232 - accuracy: 0.9667 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.9750 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1079 - accuracy: 0.9833 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1015 - accuracy: 0.9833 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0946 - accuracy: 0.9833 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0891 - accuracy: 0.9833 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "iris_data = pd.read_csv('Iris.csv')\n",
        "label_encoder = LabelEncoder()\n",
        "iris_data['species_encoded'] = label_encoder.fit_transform(iris_data['Species'])\n",
        "\n",
        "# Assuming you have a 'species' column in your dataset\n",
        "label_counts = iris_data['species_encoded'].value_counts()\n",
        "\n",
        "# Print the counts of each label\n",
        "print(label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YPB1vaeTg4e",
        "outputId": "adaa9799-c0c2-4dc5-dae1-5998efa682de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    50\n",
            "1    50\n",
            "2    50\n",
            "Name: species_encoded, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}